{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbbee1d-3ec3-46b3-a4c8-a2ba6d5faf7e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcfa45-d338-4b3f-a2a1-30ce9c97b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import resize \n",
    "from skimage.io import imread  \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sns # Beautify CM\n",
    "\n",
    "from torchvision.models import ResNet50_Weights, VGG16_Weights, EfficientNet_B0_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ceb2-f131-4c1b-89e1-f9d2467275ee",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97733b-7189-4799-9aec-7e6d420d4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"C:/Users/rishi/Desktop/JHU/Critical Infrastructure Protection/Major Project/Data Sets/Sonar/TrainSetMotionBlur\"\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Classes\n",
    "class_names = dataset.classes\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecbe51-5148-46a6-a04e-e470deb48190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b8e63-6a95-4076-8572-60f815034e83",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee84722-359c-4be2-984b-b5776126d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b1626-b874-45cd-aeca-32a5492fc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)  # For PyTorch\n",
    "np.random.seed(42)     # For NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa6bb2-2fee-4314-8105-5504dcbbdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_with_dropout(model_type, num_classes, dropout_rate=0.0):\n",
    "    if model_type == 'resnet':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),  # Add dropout before final FC\n",
    "            nn.Linear(model.fc.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    elif model_type == 'vgg':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),  # Add dropout before final FC\n",
    "            nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    elif model_type == 'efficientnet':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),  # Add dropout before final FC\n",
    "            nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fe349-328c-418b-82ba-a19d41d06c43",
   "metadata": {},
   "source": [
    "### Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20b793-b014-4005-a90f-8895bb90e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_optimizer(model, optimizer_name, learning_rate, weight_decay):\n",
    "    if optimizer_name == 'adam':\n",
    "        return optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        return optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        return optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad986dd-1804-4036-979a-b69cc1426ffe",
   "metadata": {},
   "source": [
    "## Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa683ab8-2f04-45dc-ae04-e7d849135deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, zero_division = 1)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3f9cf-459b-43bb-8d4a-eec13a849437",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4f8da-2ce0-4722-b7b6-9b738c68bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(model_types, param_grid, train_dataset, test_dataset, num_classes):\n",
    "    best_model, best_metrics, best_params = None, {'accuracy': 0}, None\n",
    "\n",
    "    for model_type in model_types:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for batch_size in param_grid['batch_size']:\n",
    "                for opt in param_grid['optimizer']:\n",
    "                    for wd in param_grid['weight_decay']:\n",
    "                        for dr in param_grid['dropout_rate']:\n",
    "                            print(f\"Training {model_type} with lr={lr}, batch_size={batch_size}, \"\n",
    "                                  f\"optimizer={opt}, weight_decay={wd}, dropout_rate={dr}\")\n",
    "\n",
    "                            # Create DataLoaders\n",
    "                            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                            # Set up the model with the specified dropout rate\n",
    "                            model = setup_model_with_dropout(model_type, num_classes, dr)\n",
    "\n",
    "                            # Set up the optimizer\n",
    "                            optimizer = setup_optimizer(model, opt, lr, wd)\n",
    "\n",
    "                            # Define the loss function\n",
    "                            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                            # Train and evaluate\n",
    "                            accuracy, _, _ = train_and_evaluate(\n",
    "                                model, optimizer, criterion, train_loader, test_loader\n",
    "                            )\n",
    "\n",
    "                            # Track the best model\n",
    "                            if accuracy > best_metrics['accuracy']:\n",
    "                                best_model = model\n",
    "                                best_metrics['accuracy'] = accuracy\n",
    "                                best_params = {\n",
    "                                    'model': model_type,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'optimizer': opt,\n",
    "                                    'weight_decay': wd,\n",
    "                                    'dropout_rate': dr\n",
    "                                }\n",
    "\n",
    "    print(f\"Best Model: {best_params['model']} | Accuracy: {best_metrics['accuracy']:.2f}% | Params: {best_params}\")\n",
    "    return best_model, best_metrics, best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2277a6-4820-499b-9c85-0854bb343704",
   "metadata": {},
   "source": [
    "## Defining Hyperparameter Grid and Running the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2534a-8832-43aa-8a91-ff9cceefbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'weight_decay': [0.0, 1e-4, 1e-3],\n",
    "    'dropout_rate': [0.0, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "model_types = ['resnet', 'vgg', 'efficientnet']\n",
    "\n",
    "best_model, best_metrics, best_params = hyperparameter_search(\n",
    "    model_types, param_grid, train_dataset, test_dataset, num_classes\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model.state_dict(), f\"best_model_{best_params['model']}.pth\")\n",
    "print(\"Best model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9918062-4f27-48d6-92b4-4e088333a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code block ran for 81764 seconds = 23 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa5ef1-2bf5-4cad-b227-c1454a9888c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, f\"best_model_{best_params['model']}_complete.pth\")\n",
    "print(\"Best model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a1d4e-e205-41c3-89ba-1b944048fcef",
   "metadata": {},
   "source": [
    "#### When you save the entire model, you are saving:\n",
    "##### -->The model architecture: The complete definition of the neural network, including its layers and structure.\n",
    "##### -->The model parameters (weights and biases): The learned values from training.\n",
    "\n",
    "#### The state dictionary only saves:\n",
    "##### -->The model's parameters: This includes weights, biases, and any other trainable tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020d284-bef0-4e4e-80ca-522e78d13e15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial Individual Models -- Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015ef18-4326-401d-8bb9-4d0c1f1b20aa",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3de63-7b81-4ed4-aaeb-096a1c867e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training and Evaluating ResNet:\")\n",
    "resnet_accuracy, resnet_report, resnet_cm = train_and_evaluate(\n",
    "    resnet_model, optimizer, criterion, train_loader, test_loader, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79113e2f-7db4-43a7-a58f-95438a63962d",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea3734-8095-4898-998f-e9eb252538bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "vgg_model.classifier[6] = nn.Linear(vgg_model.classifier[6].in_features, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training and Evaluating VGG:\")\n",
    "vgg_accuracy, vgg_report, vgg_cm = train_and_evaluate(\n",
    "    vgg_model, optimizer, criterion, train_loader, test_loader, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bdd3d-a8ff-4ced-8564-13e598245b73",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6b710-d6c7-4e2a-9990-ce3d79ddfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "efficientnet_model.classifier[1] = nn.Linear(efficientnet_model.classifier[1].in_features, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training and Evaluating EfficientNet:\")\n",
    "efficientnet_accuracy, efficientnet_report, efficientnet_cm = train_and_evaluate(\n",
    "    efficientnet_model, optimizer, criterion, train_loader, test_loader, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31cc12d-84ba-4fcd-b863-fa876546d447",
   "metadata": {},
   "source": [
    "## Print Results for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44383ba3-2d2b-4d38-a25e-46d41af10a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of Results:\")\n",
    "print(f\"ResNet Accuracy: {resnet_accuracy * 100:.2f}%\")\n",
    "print(f\"VGG Accuracy: {vgg_accuracy * 100:.2f}%\")\n",
    "print(f\"EfficientNet Accuracy: {efficientnet_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4673e-3f35-4fb5-87b2-8e62ef59bee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python10venv)",
   "language": "python",
   "name": "python10venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
